# Server Configuration
PORT=3000
WS_PORT=3001

# AI Provider Configuration
MODEL_PROVIDER=puter  # Options: openai, local, puter

# OpenAI Configuration (if using OpenAI provider)
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-3.5-turbo  # Options: gpt-3.5-turbo, gpt-4

# Local Model Configuration (if using local provider)
LOCAL_MODEL_ENDPOINT=http://localhost:11434/api/generate
LOCAL_MODEL=codellama  # Options: codellama, deepseek-coder, etc.

# Puter Configuration (FREE AI API - no key required!)
# Puter provides free AI API access through their JavaScript SDK
# No configuration needed - works out of the box!
PUTER_MODEL=gpt-3.5-turbo  # Model to use with Puter's free API

# Optional: Rate limiting
MAX_REQUESTS_PER_MINUTE=60

# Optional: Debug mode
DEBUG=ai-pair-programmer:*